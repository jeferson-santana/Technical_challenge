{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Instalação dos pacotes necessários"
      ],
      "metadata": {
        "id": "THknMebqimZ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install unidecode\n",
        "! pip install optuna\n",
        "!pip install scikit-optimize\n",
        "!pip install -U scikit-optimize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bn_q57H8Z6We",
        "outputId": "c50c776c-462d-4a9c-e1fe-30ecdd0468ae"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.6-py3-none-any.whl (235 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.9/235.9 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.3.6\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting optuna\n",
            "  Downloading optuna-3.1.1-py3-none-any.whl (365 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m365.7/365.7 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from optuna) (23.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.9/dist-packages (from optuna) (6.0)\n",
            "Collecting cmaes>=0.9.1\n",
            "  Downloading cmaes-0.9.1-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from optuna) (4.65.0)\n",
            "Collecting alembic>=1.5.0\n",
            "  Downloading alembic-1.10.4-py3-none-any.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.9/212.9 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.9/dist-packages (from optuna) (2.0.9)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from optuna) (1.22.4)\n",
            "Collecting colorlog\n",
            "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.9/dist-packages (from alembic>=1.5.0->optuna) (4.5.0)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.9/dist-packages (from sqlalchemy>=1.3.0->optuna) (2.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.9/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.2)\n",
            "Installing collected packages: Mako, colorlog, cmaes, alembic, optuna\n",
            "Successfully installed Mako-1.2.4 alembic-1.10.4 cmaes-0.9.1 colorlog-6.7.0 optuna-3.1.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scikit-optimize\n",
            "  Downloading scikit_optimize-0.9.0-py2.py3-none-any.whl (100 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.3/100.3 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.9/dist-packages (from scikit-optimize) (1.22.4)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.9/dist-packages (from scikit-optimize) (1.10.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.9/dist-packages (from scikit-optimize) (1.2.0)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.9/dist-packages (from scikit-optimize) (1.2.2)\n",
            "Collecting pyaml>=16.9\n",
            "  Downloading pyaml-21.10.1-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.9/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.20.0->scikit-optimize) (3.1.0)\n",
            "Installing collected packages: pyaml, scikit-optimize\n",
            "Successfully installed pyaml-21.10.1 scikit-optimize-0.9.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit-optimize in /usr/local/lib/python3.9/dist-packages (0.9.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.9/dist-packages (from scikit-optimize) (1.2.0)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.9/dist-packages (from scikit-optimize) (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.9/dist-packages (from scikit-optimize) (1.22.4)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.9/dist-packages (from scikit-optimize) (1.10.1)\n",
            "Requirement already satisfied: pyaml>=16.9 in /usr/local/lib/python3.9/dist-packages (from scikit-optimize) (21.10.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.9/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.20.0->scikit-optimize) (3.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import das bibliotecas"
      ],
      "metadata": {
        "id": "7VlYn9shOx7s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import io\n",
        "from google.colab import files\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "import io\n",
        "import unidecode\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import sklearn.metrics as metrics\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "import matplotlib.pyplot as plt\n",
        "from random import randrange\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn import set_config\n",
        "from sklearn.preprocessing import FunctionTransformer, RobustScaler\n",
        "from collections import Counter\n",
        "import random\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler, KBinsDiscretizer\n",
        "from imblearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from skopt.space import Real, Integer, Categorical\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.metrics import classification_report\n",
        "from skopt import BayesSearchCV\n",
        "from joblib import parallel_backend\n",
        "from sklearn.metrics import make_scorer, precision_score"
      ],
      "metadata": {
        "id": "eo_H2w-vO0-d"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Carga dos dados"
      ],
      "metadata": {
        "id": "AZBOTXnbO1k2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregar o arquivo\n",
        "uploaded = files.upload()\n",
        "# Especificar a codificação correta\n",
        "df = pd.read_csv(io.BytesIO(uploaded['full_devices.csv']), encoding='ISO-8859-1')"
      ],
      "metadata": {
        "id": "wpi0XSreO3SQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "6a48fdb5-24b4-4b0b-d821-74bdccd1ed92"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-925e0cc2-96bf-4d14-b525-c5befca31161\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-925e0cc2-96bf-4d14-b525-c5befca31161\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving full_devices.csv to full_devices.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Avaliação da base"
      ],
      "metadata": {
        "id": "vZYv9ynwZKZ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "9XgOgelaW6sg",
        "outputId": "9a044147-645c-4a29-fe49-a4d00485a3e9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         date    device  failure  attribute1  attribute2  attribute3  \\\n",
              "0  2015-01-01  S1F01085        0   215630672          56           0   \n",
              "1  2015-01-01  S1F0166B        0    61370680           0           3   \n",
              "2  2015-01-01  S1F01E6Y        0   173295968           0           0   \n",
              "3  2015-01-01  S1F01JE0        0    79694024           0           0   \n",
              "4  2015-01-01  S1F01R2B        0   135970480           0           0   \n",
              "\n",
              "   attribute4  attribute5  attribute6  attribute7  attribute8  attribute9  \n",
              "0          52           6      407438           0           0           7  \n",
              "1           0           6      403174           0           0           0  \n",
              "2           0          12      237394           0           0           0  \n",
              "3           0           6      410186           0           0           0  \n",
              "4           0          15      313173           0           0           3  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-35de00c2-bc16-49fd-9bbd-398aa93f9aa7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>device</th>\n",
              "      <th>failure</th>\n",
              "      <th>attribute1</th>\n",
              "      <th>attribute2</th>\n",
              "      <th>attribute3</th>\n",
              "      <th>attribute4</th>\n",
              "      <th>attribute5</th>\n",
              "      <th>attribute6</th>\n",
              "      <th>attribute7</th>\n",
              "      <th>attribute8</th>\n",
              "      <th>attribute9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2015-01-01</td>\n",
              "      <td>S1F01085</td>\n",
              "      <td>0</td>\n",
              "      <td>215630672</td>\n",
              "      <td>56</td>\n",
              "      <td>0</td>\n",
              "      <td>52</td>\n",
              "      <td>6</td>\n",
              "      <td>407438</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2015-01-01</td>\n",
              "      <td>S1F0166B</td>\n",
              "      <td>0</td>\n",
              "      <td>61370680</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>403174</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2015-01-01</td>\n",
              "      <td>S1F01E6Y</td>\n",
              "      <td>0</td>\n",
              "      <td>173295968</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>237394</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2015-01-01</td>\n",
              "      <td>S1F01JE0</td>\n",
              "      <td>0</td>\n",
              "      <td>79694024</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>410186</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2015-01-01</td>\n",
              "      <td>S1F01R2B</td>\n",
              "      <td>0</td>\n",
              "      <td>135970480</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>313173</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-35de00c2-bc16-49fd-9bbd-398aa93f9aa7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-35de00c2-bc16-49fd-9bbd-398aa93f9aa7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-35de00c2-bc16-49fd-9bbd-398aa93f9aa7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 344
        },
        "id": "wNKl_1vtXMFY",
        "outputId": "9bbbc345-19e1-4ff5-8808-e1aa6d13cb95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             failure    attribute1     attribute2     attribute3  \\\n",
              "count  124494.000000  1.244940e+05  124494.000000  124494.000000   \n",
              "mean        0.000851  1.223881e+08     159.484762       9.940455   \n",
              "std         0.029167  7.045933e+07    2179.657730     185.747321   \n",
              "min         0.000000  0.000000e+00       0.000000       0.000000   \n",
              "25%         0.000000  6.128476e+07       0.000000       0.000000   \n",
              "50%         0.000000  1.227974e+08       0.000000       0.000000   \n",
              "75%         0.000000  1.833096e+08       0.000000       0.000000   \n",
              "max         1.000000  2.441405e+08   64968.000000   24929.000000   \n",
              "\n",
              "          attribute4     attribute5     attribute6     attribute7  \\\n",
              "count  124494.000000  124494.000000  124494.000000  124494.000000   \n",
              "mean        1.741120      14.222669  260172.657726       0.292528   \n",
              "std        22.908507      15.943028   99151.078547       7.436924   \n",
              "min         0.000000       1.000000       8.000000       0.000000   \n",
              "25%         0.000000       8.000000  221452.000000       0.000000   \n",
              "50%         0.000000      10.000000  249799.500000       0.000000   \n",
              "75%         0.000000      12.000000  310266.000000       0.000000   \n",
              "max      1666.000000      98.000000  689161.000000     832.000000   \n",
              "\n",
              "          attribute8     attribute9  \n",
              "count  124494.000000  124494.000000  \n",
              "mean        0.292528      12.451524  \n",
              "std         7.436924     191.425623  \n",
              "min         0.000000       0.000000  \n",
              "25%         0.000000       0.000000  \n",
              "50%         0.000000       0.000000  \n",
              "75%         0.000000       0.000000  \n",
              "max       832.000000   18701.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-92f625c5-38f0-4501-a315-14c313744c87\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>failure</th>\n",
              "      <th>attribute1</th>\n",
              "      <th>attribute2</th>\n",
              "      <th>attribute3</th>\n",
              "      <th>attribute4</th>\n",
              "      <th>attribute5</th>\n",
              "      <th>attribute6</th>\n",
              "      <th>attribute7</th>\n",
              "      <th>attribute8</th>\n",
              "      <th>attribute9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>124494.000000</td>\n",
              "      <td>1.244940e+05</td>\n",
              "      <td>124494.000000</td>\n",
              "      <td>124494.000000</td>\n",
              "      <td>124494.000000</td>\n",
              "      <td>124494.000000</td>\n",
              "      <td>124494.000000</td>\n",
              "      <td>124494.000000</td>\n",
              "      <td>124494.000000</td>\n",
              "      <td>124494.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.000851</td>\n",
              "      <td>1.223881e+08</td>\n",
              "      <td>159.484762</td>\n",
              "      <td>9.940455</td>\n",
              "      <td>1.741120</td>\n",
              "      <td>14.222669</td>\n",
              "      <td>260172.657726</td>\n",
              "      <td>0.292528</td>\n",
              "      <td>0.292528</td>\n",
              "      <td>12.451524</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.029167</td>\n",
              "      <td>7.045933e+07</td>\n",
              "      <td>2179.657730</td>\n",
              "      <td>185.747321</td>\n",
              "      <td>22.908507</td>\n",
              "      <td>15.943028</td>\n",
              "      <td>99151.078547</td>\n",
              "      <td>7.436924</td>\n",
              "      <td>7.436924</td>\n",
              "      <td>191.425623</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.128476e+07</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>221452.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.227974e+08</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>249799.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.833096e+08</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>310266.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.441405e+08</td>\n",
              "      <td>64968.000000</td>\n",
              "      <td>24929.000000</td>\n",
              "      <td>1666.000000</td>\n",
              "      <td>98.000000</td>\n",
              "      <td>689161.000000</td>\n",
              "      <td>832.000000</td>\n",
              "      <td>832.000000</td>\n",
              "      <td>18701.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-92f625c5-38f0-4501-a315-14c313744c87')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-92f625c5-38f0-4501-a315-14c313744c87 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-92f625c5-38f0-4501-a315-14c313744c87');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0_R-E62ZO7Q",
        "outputId": "73c05151-109f-4586-b619-17dba1b1d3be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 124494 entries, 0 to 124493\n",
            "Data columns (total 12 columns):\n",
            " #   Column      Non-Null Count   Dtype \n",
            "---  ------      --------------   ----- \n",
            " 0   date        124494 non-null  object\n",
            " 1   device      124494 non-null  object\n",
            " 2   failure     124494 non-null  int64 \n",
            " 3   attribute1  124494 non-null  int64 \n",
            " 4   attribute2  124494 non-null  int64 \n",
            " 5   attribute3  124494 non-null  int64 \n",
            " 6   attribute4  124494 non-null  int64 \n",
            " 7   attribute5  124494 non-null  int64 \n",
            " 8   attribute6  124494 non-null  int64 \n",
            " 9   attribute7  124494 non-null  int64 \n",
            " 10  attribute8  124494 non-null  int64 \n",
            " 11  attribute9  124494 non-null  int64 \n",
            "dtypes: int64(10), object(2)\n",
            "memory usage: 11.4+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Separação da base para validação"
      ],
      "metadata": {
        "id": "guKa-WVuizPK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_size = round(df.shape[0] * 0.2)\n",
        "X_train = df.drop(['failure', 'date', 'device'], axis=1).iloc[val_size:].copy()\n",
        "y_train = df['failure'].iloc[val_size:].copy()\n",
        "\n",
        "X_val = df.drop(['failure', 'date', 'device'], axis=1).iloc[:val_size].copy()\n",
        "y_val = df['failure'].iloc[:val_size].copy()"
      ],
      "metadata": {
        "id": "PBvG8ILyi8H3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modelagem"
      ],
      "metadata": {
        "id": "Zrq-JWCbZ0O8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Decision Tree com Random Search"
      ],
      "metadata": {
        "id": "__U0W_M0vdX_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definição do pipeline com a normalização, oversampling e modelo de árvore de decisão\n",
        "pipeline = make_pipeline(StandardScaler(),\n",
        "                         SMOTE(random_state=42),\n",
        "                         DecisionTreeClassifier(random_state=42, class_weight='balanced'))\n",
        "\n",
        "# Definição dos parâmetros para teste\n",
        "param_dist = {\n",
        "    'decisiontreeclassifier__max_depth': [2, 4, 6, 8, 10],\n",
        "    'decisiontreeclassifier__min_samples_split': [2, 4, 6, 8, 10],\n",
        "    'decisiontreeclassifier__min_samples_leaf': [1, 2, 3, 4, 5],\n",
        "    'smote__sampling_strategy': ['minority', 'not majority', 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
        "    'decisiontreeclassifier__criterion': ['gini', 'entropy']\n",
        "}\n",
        "\n",
        "# Execução do RandomizedSearchCV\n",
        "rand_search = RandomizedSearchCV(pipeline, param_distributions=param_dist,\n",
        "                                 cv=5, scoring='f1', n_iter=20,\n",
        "                                 random_state=42)\n",
        "rand_search.fit(X_train, y_train)\n",
        "\n",
        "# Treinamento com a melhor combinação de parâmetros\n",
        "best_pipeline = rand_search.best_estimator_\n",
        "best_pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Predição nos dados de treino\n",
        "y_pred_train = best_pipeline.predict(X_train)\n",
        "print(\"Train Classification Report:\")\n",
        "print(classification_report(y_train, y_pred_train))\n",
        "\n",
        "# Predição nos dados de validação\n",
        "y_pred_val = best_pipeline.predict(X_val)\n",
        "print(\"Validation Classification Report:\")\n",
        "print(classification_report(y_val, y_pred_val))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7wsUn9-aAvV",
        "outputId": "a2d0c23d-17c8-4b34-d2ee-b7ea3fae54c8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.94      0.97     99513\n",
            "           1       0.01      0.56      0.02        82\n",
            "\n",
            "    accuracy                           0.94     99595\n",
            "   macro avg       0.50      0.75      0.49     99595\n",
            "weighted avg       1.00      0.94      0.97     99595\n",
            "\n",
            "Validation Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.93      0.97     24875\n",
            "           1       0.01      0.67      0.02        24\n",
            "\n",
            "    accuracy                           0.93     24899\n",
            "   macro avg       0.50      0.80      0.49     24899\n",
            "weighted avg       1.00      0.93      0.96     24899\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature importance\n",
        "tree_model = best_pipeline.named_steps['decisiontreeclassifier']\n",
        "feat_importances = pd.Series(tree_model.feature_importances_, index=X_train.columns)\n",
        "print(\"Feature Importance:\")\n",
        "print(feat_importances)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLaLEK85iDqa",
        "outputId": "d0c7e49a-db92-4850-92f6-1f6d3ae543a1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Importance:\n",
            "attribute1    0.065471\n",
            "attribute2    0.122739\n",
            "attribute3    0.010529\n",
            "attribute4    0.457462\n",
            "attribute5    0.093243\n",
            "attribute6    0.146638\n",
            "attribute7    0.041792\n",
            "attribute8    0.036901\n",
            "attribute9    0.025226\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Definição do pipeline com a normalização, oversampling e modelo de árvore de decisão\n",
        "pipeline = make_pipeline(StandardScaler(),\n",
        "                         SMOTE(random_state=42),\n",
        "                         DecisionTreeClassifier(random_state=42, class_weight={0: 1, 1: 5}, criterion='entropy'))\n",
        "\n",
        "# Definição dos parâmetros para teste\n",
        "param_dist = {\n",
        "    'decisiontreeclassifier__max_depth': [2, 4, 6, 8, 10],\n",
        "    'decisiontreeclassifier__min_samples_split': [2, 4, 6, 8, 10],\n",
        "    'decisiontreeclassifier__min_samples_leaf': [1, 2, 3, 4, 5],\n",
        "    'smote__sampling_strategy': ['minority', 'not majority', 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
        "}\n",
        "\n",
        "# Execução do RandomizedSearchCV\n",
        "rand_search = RandomizedSearchCV(pipeline, param_distributions=param_dist,\n",
        "                                 cv=5, scoring='f1', n_iter=20,\n",
        "                                 random_state=42)\n",
        "rand_search.fit(X_train, y_train)\n",
        "\n",
        "# Treinamento com a melhor combinação de parâmetros\n",
        "best_pipeline = rand_search.best_estimator_\n",
        "best_pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Predição nos dados de treino\n",
        "y_pred_train = best_pipeline.predict(X_train)\n",
        "print(\"Train Classification Report:\")\n",
        "print(classification_report(y_train, y_pred_train))\n",
        "\n",
        "# Predição nos dados de validação\n",
        "y_pred_val = best_pipeline.predict(X_val)\n",
        "print(\"Validation Classification Report:\")\n",
        "print(classification_report(y_val, y_pred_val))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-pR5SlHifVc",
        "outputId": "49f4bbb0-6a0c-4cb1-8ecc-ca0aeff82771"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.93      0.96     99513\n",
            "           1       0.01      0.90      0.02        82\n",
            "\n",
            "    accuracy                           0.93     99595\n",
            "   macro avg       0.51      0.92      0.49     99595\n",
            "weighted avg       1.00      0.93      0.96     99595\n",
            "\n",
            "Validation Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.92      0.96     24875\n",
            "           1       0.01      0.58      0.01        24\n",
            "\n",
            "    accuracy                           0.92     24899\n",
            "   macro avg       0.50      0.75      0.49     24899\n",
            "weighted avg       1.00      0.92      0.96     24899\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Forest - Foco no equilibrio da identificação da falha"
      ],
      "metadata": {
        "id": "I1tgaVa7vZUy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Separa os dados em treino e teste\n",
        "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
        "    df.drop(['failure', 'date', 'device'], axis=1), df['failure'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Separa os dados de treino e validação\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train_val, y_train_val, test_size=0.25, random_state=42)\n",
        "\n",
        "# Define o modelo de classificação\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Define a estratégia de oversampling\n",
        "oversample = SMOTE(sampling_strategy=0.1, random_state=42)\n",
        "\n",
        "# Aplica a técnica de oversampling no conjunto de treino\n",
        "X_resampled, y_resampled = oversample.fit_resample(X_train, y_train)\n",
        "\n",
        "# Treina o modelo com o conjunto de treino após resemplig usando validação cruzada\n",
        "scores = cross_val_score(model, X_resampled, y_resampled, cv=5)\n",
        "\n",
        "# Treina o modelo com o conjunto de treino após resemplig\n",
        "model.fit(X_resampled, y_resampled)\n",
        "\n",
        "# Realiza as predições no conjunto de teste\n",
        "y_pred_test = model.predict(X_test)\n",
        "\n",
        "# Calcula as métricas de avaliação para as previsões e rótulos verdadeiros do conjunto de teste\n",
        "report_test = classification_report(y_test, y_pred_test)\n",
        "print(\"Relatório de classificação para os dados de teste:\\n\", report_test)\n",
        "\n",
        "# Realiza as predições no conjunto de validação\n",
        "y_pred_val = model.predict(X_val)\n",
        "\n",
        "# Calcula as métricas de avaliação para as previsões e rótulos verdadeiros do conjunto de validação\n",
        "report_val = classification_report(y_val, y_pred_val)\n",
        "print(\"Relatório de classificação para os dados de validação:\\n\", report_val)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMb5VrExmQ42",
        "outputId": "956d2498-55ef-4bbd-e2c3-b538a837bc58"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Relatório de classificação para os dados de teste:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     24881\n",
            "           1       0.14      0.22      0.17        18\n",
            "\n",
            "    accuracy                           1.00     24899\n",
            "   macro avg       0.57      0.61      0.59     24899\n",
            "weighted avg       1.00      1.00      1.00     24899\n",
            "\n",
            "Relatório de classificação para os dados de validação:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     24878\n",
            "           1       0.08      0.10      0.09        21\n",
            "\n",
            "    accuracy                           1.00     24899\n",
            "   macro avg       0.54      0.55      0.54     24899\n",
            "weighted avg       1.00      1.00      1.00     24899\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random forest peso maior na manutenção"
      ],
      "metadata": {
        "id": "w5-XB--m9taL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Separa os dados em treino e teste\n",
        "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
        "    df.drop(['failure', 'date', 'device'], axis=1), df['failure'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Separa os dados de treino e validação\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train_val, y_train_val, test_size=0.25, random_state=42)\n",
        "\n",
        "# Define a estratégia de oversampling\n",
        "oversample = SMOTE(sampling_strategy=0.1, random_state=42)\n",
        "\n",
        "# Definição do espaço de busca para os hiperparâmetros\n",
        "param_space = {\n",
        "    'n_estimators': Integer(50, 100),\n",
        "    'max_depth': Integer(5, 10),\n",
        "    'min_samples_split': Integer(2, 5),\n",
        "    'min_samples_leaf': Integer(1, 3),\n",
        "    'bootstrap': Categorical([True, False])\n",
        "}\n",
        "\n",
        "# Define uma função de pontuação personalizada para calcular a precisão e recall da classe 1\n",
        "def custom_scorer(y_true, y_pred):\n",
        "    score = f1_score(y_true, y_pred, pos_label=1)\n",
        "    return score\n",
        "\n",
        "# Define o modelo de classificação com o parâmetro \"class_weight\"\n",
        "model = RandomForestClassifier(random_state=42, class_weight={0: 1, 1: 5})\n",
        "\n",
        "# Normaliza os dados de treino e validação\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_val = scaler.transform(X_val)\n",
        "\n",
        "# Converte a função custom_scorer em um scorer para ser usado pelo BayesSearchCV\n",
        "scorer = make_scorer(custom_scorer)\n",
        "\n",
        "# Realiza a busca por hiperparâmetros em paralelo\n",
        "with parallel_backend('multiprocessing', n_jobs=-1):\n",
        "    bayes_search = BayesSearchCV(\n",
        "        estimator=model, search_spaces=param_space, cv=5, scoring=scorer, n_iter=5, n_jobs=-1\n",
        "    )\n",
        "    bayes_search.fit(X_train, y_train)\n",
        "\n",
        "# Imprime os melhores hiperparâmetros encontrados\n",
        "print(\"Melhores hiperparâmetros encontrados:\")\n",
        "print(bayes_search.best_params_)\n",
        "\n",
        "# Treina o modelo com os melhores hiperparâmetros e o conjunto de treino após resemplig\n",
        "best_model = bayes_search.best_estimator_\n",
        "X_resampled, y_resampled = oversample.fit_resample(X_train, y_train)\n",
        "best_model.fit(X_resampled, y_resampled)\n",
        "\n",
        "# Normaliza os dados de teste\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Realiza as predições no conjunto de treino\n",
        "y_pred_train = best_model.predict(X_resampled)\n",
        "\n",
        "# Calcula as métricas de avaliação para as previsões e rótulos verdadeiros do conjunto de treino\n",
        "report_train = classification_report(y_resampled, y_pred_train)\n",
        "print(\"Relatório de classificação para os dados de treino:\\n\", report_train)\n",
        "\n",
        "# Realiza as predições no conjunto de teste\n",
        "y_pred_test = best_model.predict(X_test)\n",
        "\n",
        "# Calcula as métricas de avaliação para as previsões e rótulos verdadeiros do conjunto de teste\n",
        "report_test = classification_report(y_test, y_pred_test)\n",
        "print(\"Relatório de classificação para os dados de teste:\\n\", report_test)\n",
        "\n",
        "# Realiza as predições no conjunto de validação\n",
        "y_pred_val = best_model.predict(X_val)\n",
        "\n",
        "# Calcula as métricas de avaliação para as previsões e rótulos verdadeiros do conjunto de validação\n",
        "report_val = classification_report(y_val, y_pred_val)\n",
        "print(\"Relatório de classificação para os dados de validação:\\n\", report_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQzjVezGmRCJ",
        "outputId": "c6bb68bd-8810-4804-c822-7d86b3647d89"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Melhores hiperparâmetros encontrados:\n",
            "OrderedDict([('bootstrap', True), ('max_depth', 7), ('min_samples_leaf', 2), ('min_samples_split', 3), ('n_estimators', 100)])\n",
            "Relatório de classificação para os dados de treino:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.88      0.93     74629\n",
            "           1       0.89      0.99      0.94     74629\n",
            "\n",
            "    accuracy                           0.94    149258\n",
            "   macro avg       0.94      0.94      0.94    149258\n",
            "weighted avg       0.94      0.94      0.94    149258\n",
            "\n",
            "Relatório de classificação para os dados de teste:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.88      0.94     24881\n",
            "           1       0.00      0.72      0.01        18\n",
            "\n",
            "    accuracy                           0.88     24899\n",
            "   macro avg       0.50      0.80      0.47     24899\n",
            "weighted avg       1.00      0.88      0.93     24899\n",
            "\n",
            "Relatório de classificação para os dados de validação:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.88      0.94     24878\n",
            "           1       0.00      0.62      0.01        21\n",
            "\n",
            "    accuracy                           0.88     24899\n",
            "   macro avg       0.50      0.75      0.47     24899\n",
            "weighted avg       1.00      0.88      0.93     24899\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Separa os dados em treino e teste\n",
        "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
        "    df.drop(['failure', 'date', 'device'], axis=1), df['failure'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Separa os dados de treino e validação\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train_val, y_train_val, test_size=0.25, random_state=42)\n",
        "\n",
        "# Define a estratégia de oversampling\n",
        "oversample = SMOTE(sampling_strategy=0.1, random_state=42)\n",
        "\n",
        "# Definição do espaço de busca para os hiperparâmetros\n",
        "param_space = {\n",
        "    'n_estimators': Integer(50, 100),\n",
        "    'max_depth': Integer(5, 10),\n",
        "    'min_samples_split': Integer(2, 5),\n",
        "    'min_samples_leaf': Integer(1, 3),\n",
        "    'bootstrap': Categorical([True, False])\n",
        "}\n",
        "\n",
        "# Define uma função de pontuação personalizada para calcular a precisão e recall da classe 1\n",
        "def custom_scorer(y_true, y_pred):\n",
        "    score = f1_score(y_true, y_pred, pos_label=1)\n",
        "    return score\n",
        "\n",
        "# Define o modelo de classificação com o parâmetro \"class_weight\"\n",
        "model = RandomForestClassifier(random_state=42, class_weight={0: 1, 1: 5})\n",
        "\n",
        "# Normaliza os dados de treino e validação\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_val = scaler.transform(X_val)\n",
        "\n",
        "# Converte a função custom_scorer em um scorer para ser usado pelo BayesSearchCV\n",
        "scorer = make_scorer(custom_scorer)\n",
        "\n",
        "# Realiza a busca por hiperparâmetros em paralelo\n",
        "with parallel_backend('multiprocessing', n_jobs=-1):\n",
        "    bayes_search = BayesSearchCV(\n",
        "        estimator=model, search_spaces=param_space, cv=5, scoring=scorer, n_iter=5, n_jobs=-1\n",
        "    )\n",
        "    bayes_search.fit(X_train, y_train)\n",
        "\n",
        "# Imprime os melhores hiperparâmetros encontrados\n",
        "print(\"Melhores hiperparâmetros encontrados:\")\n",
        "print(bayes_search.best_params_)\n",
        "\n",
        "# Treina o modelo com os melhores hiperparâmetros e o conjunto de treino após resemplig\n",
        "best_model = bayes_search.best_estimator_\n",
        "X_resampled, y_resampled = oversample.fit_resample(X_train, y_train)\n",
        "best_model.fit(X_resampled, y_resampled)\n",
        "\n",
        "# Normaliza os dados de teste\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Realiza as predições no conjunto de treino\n",
        "y_pred_train = np.argmax(best_model.predict_proba(X_resampled), axis=1)\n",
        "\n",
        "# Calcula as métricas de avaliação para as previsões e rótulos verdadeiros do conjunto de treino\n",
        "report_train = classification_report(y_resampled, y_pred_train)\n",
        "print(\"Relatório de classificação para os dados de treino:\\n\", report_train)\n",
        "\n",
        "# Realiza as predições no conjunto de teste\n",
        "y_pred_test = np.argmax(best_model.predict_proba(X_test), axis=1)\n",
        "\n",
        "# Calcula as métricas de avaliação para as previsões e rótulos verdadeiros do conjunto de teste\n",
        "report_test = classification_report(y_test, y_pred_test)\n",
        "print(\"Relatório de classificação para os dados de teste:\\n\", report_test)\n",
        "\n",
        "# Realiza as predições no conjunto de validação\n",
        "y_pred_val = np.argmax(best_model.predict_proba(X_val), axis=1)\n",
        "\n",
        "# Calcula as métricas de avaliação para as previsões e rótulos verdadeiros do conjunto de validação\n",
        "report_val = classification_report(y_val, y_pred_val)\n",
        "print(\"Relatório de classificação para os dados de validação:\\n\", report_val)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oaTPJriPgx6J",
        "outputId": "7ccf2d47-f0bc-4988-c62f-cc21bc7049fc"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Relatório de classificação para os dados de treino:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98     74629\n",
            "           1       0.80      0.85      0.82      7462\n",
            "\n",
            "    accuracy                           0.97     82091\n",
            "   macro avg       0.89      0.91      0.90     82091\n",
            "weighted avg       0.97      0.97      0.97     82091\n",
            "\n",
            "Relatório de classificação para os dados de teste:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99     24881\n",
            "           1       0.02      0.50      0.03        18\n",
            "\n",
            "    accuracy                           0.98     24899\n",
            "   macro avg       0.51      0.74      0.51     24899\n",
            "weighted avg       1.00      0.98      0.99     24899\n",
            "\n",
            "Relatório de classificação para os dados de validação:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99     24878\n",
            "           1       0.01      0.29      0.02        21\n",
            "\n",
            "    accuracy                           0.98     24899\n",
            "   macro avg       0.50      0.63      0.50     24899\n",
            "weighted avg       1.00      0.98      0.99     24899\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predição em produção para falha"
      ],
      "metadata": {
        "id": "G983SCAhgmZ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Leitura do arquivo em produção\n",
        "# df = pd.read_csv(io.BytesIO(uploaded['devices_prod.csv']), encoding='ISO-8859-1')\n",
        "\n",
        "# # Normaliza os dados do dataframe\n",
        "# X_prod = scaler.transform(df_prod)\n",
        "\n",
        "# # Realiza as predições no conjunto de produção\n",
        "# proba_falha = best_model.predict_proba(X_prod)[:,1]\n",
        "\n",
        "# # Adiciona a coluna de probabilidade de falha ao dataframe\n",
        "# df_prod['proba_falha'] = proba_falha"
      ],
      "metadata": {
        "id": "y8LeVj6raV7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Análises/Oportunidades\n",
        "1. Oportunidade rodar o algoritmo em máquinas super potentes com mais núcleos visando aplicar gridsearch ou randomsearch em busca da melhor combinação de parâmetros\n",
        "2. Coletar mais dados com a classe de falhar positiva\n",
        "3. Coletar mais features\n",
        "4. O melhor resultado que conseguimos com as limitações de hardware e base de dados leva a dois caminhos um seria um valor de recall da classe positiva maior visando acertar mais falando sobre a probabilidade alta de falha, contudo iria errar mais dizendo em casos que não terá falha e dizer que terá, ou buscar equilibrar precision e recall."
      ],
      "metadata": {
        "id": "3eE8RgpnW1lW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Metodologia\n",
        "1. Apliquei estratégicas para lhe dar com a base desbalanceada com o SMOTE que cria exemplos sintéticos com base em interpolação encontrando os k vizinhos mais próximos.\n",
        " 2. Testei alguns dos modelos mais comuns e performáticos para esse tipo de tarefa com o árvore de decisão, random forest e XGBoost.\n",
        " 3. Normalizei os dados, pois haviam features com escala muito diferente das outras, o que poderia impactar o resultado\n",
        " 4. Foquei na análise do F1-Score como métrica para desafios desse tipo\n",
        " 5. Utilizei algoritmos de busca para busca a melhor combinação de hiperparâmetros(Apenas o GridSearch poderia garantir o ótimo global, os demais apenas sub ótimos) a medida do possivel dado a necessidade de alta computação.\n",
        " 6. Criei funções para tentar equilibrar os valores entre precision e recall\n",
        " 7. Utilizei pipeline para organizar o código e evitar vazamento de dados\n"
      ],
      "metadata": {
        "id": "KNPxK0tokx_G"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aZQj1rYXkxV9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}